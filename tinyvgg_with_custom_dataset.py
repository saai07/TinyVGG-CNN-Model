# -*- coding: utf-8 -*-
"""TinyVGG_WITH_custom_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Os0Z3WDVUIN2FCw6N3QF2DC4GAItu_hs
"""



"""##0. Impoprting PyTorch and setting up device-agnostic code"""

#IMPORTing libary

import torch
from torch import nn

torch.__version__

# Setup the device agnostic code
device = "cuda" if torch.cuda.is_available() else "cpu"
device

"""#Get data

Our data set is the subset of   Food101 datasets


Food101 starts 101 different classes of foods and 1000 images per class (750 training and 250 testing)

our dataset start with 3 classes of food and only 10 %percent of images (75 training and 25 testing)
"""

import requests
import zipfile

from pathlib import Path
#seting path to the data folder

data_path = Path('data/')
image_path = data_path / "pizza_steak_sushi"

#if the image folder doesnt exist , downlaod it and prepare it.......

if image_path.is_dir():
  print(f"{image_path} directory already exist")
else:
  print(f" {image_path} does not exist , creating one")
  image_path.mkdir(parents=True, exist_ok =True)
#Downlaoding the data
with open(data_path/"pizza_steak_sushi.zip", "wb") as f:
  request =requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/refs/heads/main/data/pizza_steak_sushi.zip")
  print("Downlaoding pizza steak sushi data ....")
  f.write(request.content)

with zipfile.ZipFile(data_path/ "pizza_steak_sushi.zip" , "r") as zip_ref:
  print("Unzipping the pizza_steak_sushi data")
  zip_ref.extractall(image_path)

"""## 2 Becoming one with data (data preparation and exploration)"""

import os
def walk_through_dir(dir_path):
  """WALK THROUGH THE DATA PATH RETURNING ITS CONTENT """
  for dirpath , dirnames , filesnames in os.walk(dir_path):
    print(f"There are {len(dirnames)} directories in {len(filesnames)} images in{dirpath} .")

walk_through_dir(image_path)

"""##2.1 visuliasing t5he images
1. Get all the image path using Python's `random .choice()`

2. Get all of the images paths

3. Get the images class names , using  `'Pathlib.Path.Parent.stem'`

4. Since we are working with image , lets open teh image with` pytorch' PIL`

"""

image_path

import random
from PIL import Image

#random.seed(42)

image_path_list = list(image_path.glob("*/*/*.jpg"))


random_image_path = random.choice(image_path_list)

print(random_image_path)

#3 getting image from path name (the images class is the name of the directory where the image is stored)

image_class = random_image_path.parent.stem

print(image_class)

4. #opening image
img = Image.open(random_image_path)


#printing metadata
print(f" Random image path {random_image_path}")
print(f" Image class : { image_class}")
print(f" Image height : {img.height} ")
print(f" Image width : {img.width}")
img

import numpy as np
import matplotlib.pyplot as plt

#turing image to numpy array
img_as_array = np.asarray(img)


#plot the image with matplotlib

plt.figure(figsize =(10,7))
plt.imshow(img_as_array)
plt.title(f" Image class  : {image_class} | image_shape : {img_as_array.shape} --> [height , width , color channels]")
plt.axis(False);

img_as_array

"""## 3 Transforming data

Before we can use our image data with PyTorch

1.Turn my target  data into tensor (here it is numerical repesention of the image data)

2.Turning IT into a `torch.utils.data.Dataset` and subsequently a `torch.utils.data.DataLoader`

# 3.1 Transforming data with `torchvision.trasnsforms`

Transform help to get your image ready to be used with a model/perform data augmentation
"""

import torch
from torch.utils.data import DataLoader
from torchvision import datasets , transforms

# Write a transform for image
data_transform =transforms.Compose([
    #Resize our image to 64x 64
    transforms.Resize(size=(64, 64)),
    #Flip the images randomly on the horizontal
    transforms.RandomHorizontalFlip(p=0.5),
    #Turn the image into a torch.Tensor
    transforms.ToTensor()
])

data_transform(img).shape

def plot_transformed_image(image_path , transform , n , seed =None):
  """
Selects random images from a path images and load / transforms
them then plots the originals vs the transformed version
"""
  if seed:
    random.seed(seed)
  random_image_path = random.sample(image_path , k =n)
  for image_path in random_image_path :
    with Image.open(image_path) as f:
      fig, ax = plt.subplots(nrows = 1, ncols=2)
      ax[0].imshow(f)
      ax[0].set_title (f"Original\nSize: {f.size}")
      ax[0].axis("off")



      #Transform and plot target image
      transformed_image = transform(f).permute(1,2,0) # here permute we will change shape form (C,H,W) --> (H,W,C)
      ax[1].imshow(transformed_image)
      ax[1].set_title(f"Transformed\nSize : {transformed_image.shape}")
      ax[1].axis("off")

      fig.suptitle(f" Class : {image_path.parent.stem}", fontsize = 16)

plot_transformed_image(image_path= image_path_list, transform = data_transform,
                       n=1, seed = 2)

test_dir = "/content/data/pizza_steak_sushi/test"
train_dir = "/content/data/pizza_steak_sushi/train"

from torchvision import datasets

train_data = datasets.ImageFolder(root = train_dir ,
                                  transform = data_transform,target_transform= None)

test_data = datasets.ImageFolder(root = test_dir ,
                                  transform =data_transform,target_transform= None)


train_data , test_data

#Get the class names
class_names_t = train_data.classes
class_names_t

#Get class names as dict

class_dict =train_data.class_to_idx
class_dict

#cheacking length
len(train_data) , len(test_data)

#index on the train_data Datasets to get a single image and label
img ,label =train_data[0][0] ,train_data [0][1]
print(f" Image tensor :\n {img}")
print(f"Image shape : {img.shape}")
print(f" Iamage datatype : {img.dtype}")
print(f"Image label : {label}")
print(" Image label {label.dtype}")

class_names_t[label]

#Rearrange the order dimension
img_permute = img.permute(1,2,0)

#printing out the difference shape
print(f"Orginals shape {img.shape} | permute step {img_permute.shape}")

#Plot the image
plt.figure(figsize = (10 , 7))
plt.imshow(img_permute)
plt.axis("off")
plt.title(class_names_t[label], fontsize=14)

"""#4.1 Turning loaded images into `DataLoader`
A `DataLaoder is going to helps us to turn our `datasets` into iterables and we cna customise the batch_size so our model can see batch_size images at a time

"""

#Trun Train and test datasets into DataLoader's

from torch.utils.data import DataLoader

Batch_size = 32
train_dataLoader = DataLoader(dataset= train_data, batch_size = 32, num_workers = 1, shuffle = True)
test_dataLaoder = DataLoader(dataset = test_data , batch_size = 32, num_workers =1  , shuffle =  False)

img , label = next(iter(train_dataLoader))

print(f"Iamge shape {img.shape} --> batch_size , color_channel , height , width")
print(f"Label : {label.shape}")

"""# 5 Option 2 :Loading Image Data with a Custom `Dataset`

1. Want to be able to load images from files
2. Want to be able to get class names from the Dataset
3. Want to be able to get as dictionary from the datasets


pros:
* Can create a `Dataset` out of almost anything
* Not limited to pytorch pre-built `dataset` functions

cons:
- Even though we could create our own darasets out of almost anything its doesnt mean it will work .

- Using Custom dataet often result in us writting more code that could be provr to error or perfermancr issue
"""

import os
import pathlib
import torch


from PIL import Image
from torch.utils.data import Dataset
from torchvision import transforms
from typing import List , Tuple , Dict

"""### 5.1 Creating a helper function to get class  names

we wamnt a function to :-
1. Get the class names using `os.scandir()` to traverse a target directory (ideally the directory is in standard image classification format)
2. Raise an error if the calse names are not found
3.Turn the class names into a dict and list and return them
"""

target_directory = train_dir

print(f"Target dir is : { target_directory }")

#gettting the class names from the target directory

class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])
class_names_found

def find_classes(directory:str):

  """Finds the class Folder names in a target directory"""
  #1. Get the class names by scannning by scanning the target directory
  classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())

  if not classes :
    raise FileNotFound (f"Could not fund any class in {directory }")

  class_to_idk = {class_names_t :i for i , class_names_t in enumerate(classes) }

  return classes , class_to_idk

find_classes(target_directory)

# Write a custom dataset class (inherits from torch.utils.data.Dataset)
from torch.utils.data import Dataset

# 1. Subclass torch.utils.data.Dataset
class ImageFolderCustom(Dataset):

    # 2. Initialize with a targ_dir and transform (optional) parameter
    def __init__(self, targ_dir: str, transform=None) -> None:

        # 3. Create class attributes
        # Get all image paths
        self.paths = list(pathlib.Path(targ_dir).glob("*/*.jpg")) # note: you'd have to update this if you've got .png's or .jpeg's
        # Setup transforms
        self.transform = transform
        # Create classes and class_to_idx attributes
        self.classes, self.class_to_idx = find_classes(targ_dir)

    # 4. Make function to load images
    def load_image(self, index: int) -> Image.Image:
        "Opens an image via a path and returns it."
        image_path = self.paths[index]
        return Image.open(image_path)

    # 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)
    def __len__(self) -> int:
        "Returns the total number of samples."
        return len(self.paths)

    # 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)
    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:
        "Returns one sample of data, data and label (X, y)."
        img = self.load_image(index)
        class_name  = self.paths[index].parent.name # expects path in data_folder/class_name/image.jpeg
        class_idx = self.class_to_idx[class_name]

        # Transform if necessary
        if self.transform:
            return self.transform(img), class_idx # return data, label (X, y)
        else:
            return img, class_idx # return data, label (X, y)

"""### 5.2 Create a custom `Data` to replicate `ImageFolder`

To create Our own custom dataset we want to :

1. Subclass `torch.utils.data.Dataset`
2. Init our subclass with target directory  (the directory we'd like to get data from) as well  as a transform if we like to transform our data.target_directory
3. Create several attributes:
  - path = paths of our images
  - transform - the transform we do like to use
  -classes - a list of the target classes
  -class_dix - dict - a dict of thr target classes mapped with to integral labels
4. Create a function to `load_images()`, this function will open an image5
5. Overwrite `__len()__` method to return the length of our dataset
6. `__getitem()__` method to return a given sample when passed an index
"""

from torchvision import transforms
#create a transform
train_transforms = transforms.Compose([ transforms.Resize(size=(64,64)),
                                      transforms.RandomHorizontalFlip(p=0.5),
                                       transforms.ToTensor
])

test_transforms = transforms.Compose([transforms.Resize(size=(64,64)),
                                      #transforms.RandomHorizontalFlip(0.5),
                                      transforms.ToTensor()
                                      ])

train_data_trans = ImageFolderCustom(train_dir,train_transforms)

train_data_trans = ImageFolderCustom(train_dir,train_transforms)

test_data_trans = ImageFolderCustom(test_dir,test_transforms)

len(test_data_trans)

test_data_trans.classes

test_data_trans.class_to_idx

#check for equality between originals ImageFolder datasets and ImageDatasets

print(train_data_trans.classes == train_data.classes)
print(test_data_trans.classes == test_data.classes)

"""### 5.3 Create a function to display random image

1. Take in a `Dataset` and a number of other parameters such as class name and how many images to visualize.

2. To prevent to display getting out of hand , lets cap the number of images to see at 10

3. Set a list of random seed for reproducibility

4. Get a list of Random ample index from the target datsset.

5. set up matplotlib plot.

6. Loop through the random sample imahges and plot them withplotlib
7.Make sure the dimension of our images lines up with matplotlib(HWC)
"""

def display_random_images(dataset: torch.utils.data.Dataset,
                          classes : list[str] = None,
                          n : int = 10, display_shape:bool =  True,
                          seed : int = None):

  if n >10 :
    n = 10
    display_shape = False
    print(f"For display porpose n should't be larger than 10, setting to 10 and remove shape")

  #set the seed
  if seed:
    random.seed(seed)

  random_samples_idx = random.sample(range(len(dataset)), k=n)
  plt.figure(figsize=(16, 8))

  for i , targ_sample in enumerate(random_samples_idx):
    trag_image , trag_label = dataset[targ_sample][0],dataset[targ_sample][1]

    #7 Adjust Image tensor shape dimension for ploating
    trag_image_adjust = trag_image.permute(1,2,0)

    #plot adjusted samples
    plt.subplot(1,n,i +1)
    plt.imshow(trag_image_adjust)
    plt.axis("off")
    if classes:
      title = f" class : {classes[trag_label]}"
      if display_shape:
        title = title + f"\nshape: {trag_image_adjust.shape}"
    plt.title(title)



"""#5.4 Turn  custom loaded image into `DataLoader`s"""

from torch.utils.data import dataloader

BATCH_SIZE = 1
NUM_WORK =os.cpu_count()
train_dataLoader_custom = DataLoader(dataset = train_data, batch_size =BATCH_SIZE, num_workers = NUM_WORK,
                                     shuffle =True)
test_dataLaoder_custom =DataLoader(dataset=test_data, batch_size =BATCH_SIZE,
                                   num_workers=NUM_WORK,
                                   shuffle = False)
train_dataLoader_custom

#Get image and label from custom dataLoader
img_custom , label_custom = next(iter(train_dataLoader_custom))

img_custom.shape , label_custom.shape

"""# 6 Other from of transform (data  augmentation)

Data augumentation is the process of  artifically adding diversity to your data.
In the case of the image data , this may mean applying various image transformation to thye tarining images.


"""

from torchvision  import transforms
from torchvision.transforms import InterpolationMode

interpolation=InterpolationMode.BILINEAR
test_transforms = transforms.Compose([transforms.Resize(size=(224,224)),
                                      transforms.ToTensor])

image_path_list = list (image_path.glob("*/*/*.jpg"))

image_path_list[:10]

image_path

"""#7 TinyVGG without data augumentation
Repicating the TinyVGG architecture from the CNN Explainer website

# 7.1 Creating transform and loading data for Model 0
"""

#create simple transform

simple_transform = transforms.Compose([transforms.Resize(size=(64,64)),transforms.ToTensor])


#1 Load and transform data
from torchvision import datasets

train_data_simple = datasets.ImageFolder(root = train_dir,
                                         transform= simple_transform)

test_data_simple = datasets.ImageFolder(root = test_dir,
                                        transform= simple_transform)

#Turn the datasets into DataLoaders
import os
from torch.utils.data import DataLoader

BATCH_SIZE = 32
NUM_WORKER = os.cpu_count()

train_dataloder_simple = DataLoader(dataset= train_data_simple, batch_size = BATCH_SIZE,
                                    shuffle = True,
                                    num_workers= NUM_WORKER)

test_dataloder_simple = DataLoader(dataset= test_data_simple, batch_size = BATCH_SIZE,
                                    shuffle = False,
                                    num_workers= NUM_WORKER)

#7.2 Building a baseline model from strach

from torch import nn
class TinyVGG(nn.Module):
  def __init__ ( self , input_shape : int
                , output_shape : int
                 , hidden_unit : int):
    super().__init__()
    self.convo_1 = nn.Sequential(nn.Conv2d(in_channels= input_shape ,
                                           out_channels = hidden_unit,
                                           kernel_size = 3,
                                           stride=1,
                                           padding = 0),
                                 nn.ReLU(),
                                 nn.Conv2d( in_channels = hidden_unit,
                                          out_channels =hidden_unit,
                                          kernel_size = 3,
                                          padding = 0),
                                 nn.ReLU(),
                                 nn.MaxPool2d(kernel_size = 2 ,
                                                 stride = 2) #defult stride is equal to the kernel_size
    )
    self.convo_2 = nn.Sequential(nn.Conv2d(in_channels= hidden_unit ,
                                           out_channels = hidden_unit,
                                           kernel_size = 3,
                                           stride=1,
                                           padding = 0),
                                 nn.ReLU(),
                                 nn.Conv2d( in_channels = hidden_unit,
                                          out_channels =hidden_unit,
                                          kernel_size = 3,
                                          padding = 0),
                                 nn.ReLU(),
                                 nn.MaxPool2d(kernel_size = 2 ,
                                                 stride = 2) #defult stride is equal to the kernel_size
    )

    self.classifier = nn.Sequential(nn.Flatten(),
                                    nn.Linear(in_features  = hidden_unit *13 * 13 ,
                                              out_features = len(class_names_t)))

  def forward(self , x):
    x = self.convo_1(x)
    #print(x.shape)
    x=self.convo_2(x)
    #print(x.shape)
    x= self.classifier(x)
    #print(x.shape)
    return x
    return self.classifier(self.convo_2(self.convo_1(x)))

torch.manual_seed(42)
torch.cuda.manual_seed(42)
model_0 = TinyVGG(input_shape = 3, #NUMBER OF COLOR CHANNELS IN OUR IMAGE DATA
                  hidden_unit = 10,
                  output_shape = len(class_names_t)).to(device)
model_0

"""### Trying a forward pass on a single inages (to test the model)"""

image_batch , label_batch = next(iter(train_dataLoader))
image_batch.shape , label_batch.shape

#Forward Pass
model_0(image_batch.to(device))

"""###7.4 using `torchinfo` to get the idea of the shape trough the model"""

#Install the torch info or import

try:
  import torchinfo
except:
  !pip install torchinfo
  import torchinfo
  from torchinfo import summary
summary(model_0,input_size=[32,3,64,64])

"""#Create trains and test loops functions

`train_step()` - takes in a model dataLaoder and trains the model on the dataloader.
`test_step()` - takes in a model dataLoader and evaluates the model on the dataLoader.
"""

device = "cuda" if torch.cuda.is_available() else "cpu"

def train_step(model: torch.nn.Module,
               dataloader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               optimizer: torch.optim.Optimizer):
    # Put model in train mode
    model.train()

    # Setup train loss and train accuracy values
    train_loss, train_acc = 0, 0

    # Loop through data loader data batches
    for batch, (X, y) in enumerate(dataloader):
        # Send data to target device
        X, y = X.to(device), y.to(device)

        # 1. Forward pass
        y_pred = model(X)

        # 2. Calculate  and accumulate loss
        loss = loss_fn(y_pred, y)
        train_loss += loss.item()

        # 3. Optimizer zero grad
        optimizer.zero_grad()

        # 4. Loss backward
        loss.backward()

        # 5. Optimizer step
        optimizer.step()

        # Calculate and accumulate accuracy metrics across all batches
        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)
        train_acc += (y_pred_class == y).sum().item()/len(y_pred)

    # Adjust metrics to get average loss and accuracy per batch
    train_loss = train_loss / len(dataloader)
    train_acc = train_acc / len(dataloader)
    return train_loss, train_acc

def test_step(model: torch.nn.Module,
              dataloader: torch.utils.data.DataLoader,
              loss_fn: torch.nn.Module):
    # Put model in eval mode
    model.eval()

    # Setup test loss and test accuracy values
    test_loss, test_acc = 0, 0

    # Turn on inference context manager
    with torch.inference_mode():
        # Loop through DataLoader batches
        for batch, (X, y) in enumerate(dataloader):
            # Send data to target device
            X, y = X.to(device), y.to(device)

            # 1. Forward pass
            test_pred_logits = model(X)

            # 2. Calculate and accumulate loss
            loss = loss_fn(test_pred_logits, y)
            test_loss += loss.item()

            # Calculate and accumulate accuracy
            test_pred_labels = test_pred_logits.argmax(dim=1)
            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))

    # Adjust metrics to get average loss and accuracy per batch
    test_loss = test_loss / len(dataloader)
    test_acc = test_acc / len(dataloader)
    return test_loss, test_acc

"""###7.6 Creating a `train()` function that will combine train_function and step function"""

from tqdm.auto import tqdm

# 1. Take in various parameters required for training and test steps
def train(model: torch.nn.Module,
          train_dataloader: torch.utils.data.DataLoader,
          test_dataloader: torch.utils.data.DataLoader,
          optimizer: torch.optim.Optimizer,
          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),
          epochs: int = 5):

    # 2. Create empty results dictionary
    results = {"train_loss": [],
        "train_acc": [],
        "test_loss": [],
        "test_acc": []
    }

    # 3. Loop through training and testing steps for a number of epochs
    for epoch in tqdm(range(epochs)):
        train_loss, train_acc = train_step(model=model,
                                           dataloader=train_dataloader,
                                           loss_fn=loss_fn,
                                           optimizer=optimizer)
        test_loss, test_acc = test_step(model=model,
            dataloader=test_dataloader,
            loss_fn=loss_fn)

        # 4. Print out what's happening
        print(
            f"Epoch: {epoch+1} | "
            f"train_loss: {train_loss:.4f} | "
            f"train_acc: {train_acc:.4f} | "
            f"test_loss: {test_loss:.4f} | "
            f"test_acc: {test_acc:.4f}"
        )

        # 5. Update results dictionary
        # Ensure all data is moved to CPU and converted to float for storage
        results["train_loss"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)
        results["train_acc"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)
        results["test_loss"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)
        results["test_acc"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)

    # 6. Return the filled results at the end of the epochs
    return results

#set random seeds
torch.manual_seed(42)
torch.cuda.manual_seed(42)

NUM_EPOCHS = 30

#Recreate an instance  of TinyVGG
model_0 = TinyVGG(input_shape=3,
                  hidden_unit=10,
                  output_shape=len(train_data.classes)).to(device)
#setup loss function and a optimizer

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(params = model_0.parameters(),
                             lr = 0.001)
#start timer
from timeit import default_timer as timer
start_time = timer()

model_0_result = train(model = model_0,
                       train_dataloader= train_dataLoader,
                       test_dataloader =test_dataLaoder,
                       optimizer=optimizer,
                       epochs = NUM_EPOCHS,
                       loss_fn = loss_fn)

# End the timer and print out how long it take
end_time = timer()
print(f" Total time taken : {end_time - start_time:.3f} seconds")

sample_loss, sample_acc = train_step(
    model=model_0,  # use a sample model
    dataloader=train_dataLoader,
    loss_fn=loss_fn,
    optimizer=optimizer,

)
print(f"Sample Loss: {sample_loss}, Sample Accuracy: {sample_acc}")

# Download custom image
import requests

# Setup custom image path
custom_image_path = data_path / "frot.jpeg"

# Download the image if it doesn't already exist
if not custom_image_path.is_file():
    with open(custom_image_path, "wb") as f:
        # When downloading from GitHub, need to use the "raw" file link
        request = requests.get("https://github.com/saai07/sai../blob/main/frot.jpeg")
        print(f"Downloading {custom_image_path}...")
        f.write(request.content)
else:
    print(f"{custom_image_path} already exists, skipping download.")

import torchvision

# Load in custom image and convert the tensor values to float32
custom_image = torchvision.io.read_image(str(custom_image_path)).type(torch.float32)

# Divide the image pixel values by 255 to get them between [0, 1]
custom_image = custom_image / 255.

# Print out image data
print(f"Custom image tensor:\n{custom_image}\n")
print(f"Custom image shape: {custom_image.shape}\n")
print(f"Custom image dtype: {custom_image.dtype}")

# Create transform pipleine to resize image
custom_image_transform = transforms.Compose([
    transforms.Resize((64, 64)),
])

# Transform target image
custom_image_transformed = custom_image_transform(custom_image)

# Print out original shape and new shape
print(f"Original shape: {custom_image.shape}")
print(f"New shape: {custom_image_transformed.shape}")



model_0.eval()
with torch.inference_mode():
    # Add an extra dimension to image
    custom_image_transformed_with_batch_size = custom_image_transformed.unsqueeze(dim=0)

    # Print out different shapes
    print(f"Custom image transformed shape: {custom_image_transformed.shape}")
    print(f"Unsqueezed custom image shape: {custom_image_transformed_with_batch_size.shape}")

    # Make a prediction on image with an extra dimension
    custom_image_pred = model_0(custom_image_transformed.unsqueeze(dim=0).to(device))

# Print out prediction logits
print(f"Prediction logits: {custom_image_pred}")

# Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)
custom_image_pred_probs = torch.softmax(custom_image_pred, dim=1)
print(f"Prediction probabilities: {custom_image_pred_probs}")

# Convert prediction probabilities -> prediction labels
custom_image_pred_label = torch.argmax(custom_image_pred_probs, dim=1)
print(f"Prediction label: {custom_image_pred_label}")

# Find the predicted label
custom_image_pred_class = class_names_t[custom_image_pred_label.cpu()] # put pred label to CPU
custom_image_pred_class

def pred_and_plot_image(model: torch.nn.Module,
                        image_path: str,
                        class_names: List[str] = None,
                        transform=None,
                        device: torch.device = device):
    """Makes a prediction on a target image and plots the image with its prediction."""

    # 1. Load in image and convert the tensor values to float32
    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)

    # 2. Divide the image pixel values by 255 to get them between [0, 1]
    target_image = target_image / 255.

    # 3. Transform if necessary
    if transform:
        target_image = transform(target_image)

    # 4. Make sure the model is on the target device
    model.to(device)

    # 5. Turn on model evaluation mode and inference mode
    model.eval()
    with torch.inference_mode():
        # Add an extra dimension to the image
        target_image = target_image.unsqueeze(dim=0)

        # Make a prediction on image with an extra dimension and send it to the target device
        target_image_pred = model(target_image.to(device))

    # 6. Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)
    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)

    # 7. Convert prediction probabilities -> prediction labels
    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)

    # 8. Plot the image alongside the prediction and prediction probability
    plt.imshow(target_image.squeeze().permute(1, 2, 0)) # make sure it's the right size for matplotlib
    if class_names:
        title = f"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}"
    else:
        title = f"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}"
    plt.title(title)
    plt.axis(False);

# Pred on our custom image
pred_and_plot_image(model=model_0,
                    image_path=custom_image_path,
                    class_names=class_names_t,
                    transform=custom_image_transform,
                    device=device)





